{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras import regularizers\n",
    "from sklearn.metrics import average_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('online_shoppers_intention.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Administrative</th>\n",
       "      <th>Administrative_Duration</th>\n",
       "      <th>Informational</th>\n",
       "      <th>Informational_Duration</th>\n",
       "      <th>ProductRelated</th>\n",
       "      <th>ProductRelated_Duration</th>\n",
       "      <th>BounceRates</th>\n",
       "      <th>ExitRates</th>\n",
       "      <th>PageValues</th>\n",
       "      <th>SpecialDay</th>\n",
       "      <th>Month</th>\n",
       "      <th>OperatingSystems</th>\n",
       "      <th>Browser</th>\n",
       "      <th>Region</th>\n",
       "      <th>TrafficType</th>\n",
       "      <th>VisitorType</th>\n",
       "      <th>Weekend</th>\n",
       "      <th>Revenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Feb</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Returning_Visitor</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Feb</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Returning_Visitor</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Feb</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>Returning_Visitor</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Feb</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>Returning_Visitor</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>627.500000</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Feb</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>Returning_Visitor</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Administrative  Administrative_Duration  Informational  \\\n",
       "0               0                      0.0              0   \n",
       "1               0                      0.0              0   \n",
       "2               0                      0.0              0   \n",
       "3               0                      0.0              0   \n",
       "4               0                      0.0              0   \n",
       "\n",
       "   Informational_Duration  ProductRelated  ProductRelated_Duration  \\\n",
       "0                     0.0               1                 0.000000   \n",
       "1                     0.0               2                64.000000   \n",
       "2                     0.0               1                 0.000000   \n",
       "3                     0.0               2                 2.666667   \n",
       "4                     0.0              10               627.500000   \n",
       "\n",
       "   BounceRates  ExitRates  PageValues  SpecialDay Month  OperatingSystems  \\\n",
       "0         0.20       0.20         0.0         0.0   Feb                 1   \n",
       "1         0.00       0.10         0.0         0.0   Feb                 2   \n",
       "2         0.20       0.20         0.0         0.0   Feb                 4   \n",
       "3         0.05       0.14         0.0         0.0   Feb                 3   \n",
       "4         0.02       0.05         0.0         0.0   Feb                 3   \n",
       "\n",
       "   Browser  Region  TrafficType        VisitorType  Weekend  Revenue  \n",
       "0        1       1            1  Returning_Visitor    False    False  \n",
       "1        2       1            2  Returning_Visitor    False    False  \n",
       "2        1       9            3  Returning_Visitor    False    False  \n",
       "3        2       2            4  Returning_Visitor    False    False  \n",
       "4        3       1            4  Returning_Visitor     True    False  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X = pd.get_dummies(data=df.loc[:, df.columns != 'Revenue'], columns = ['Month', 'OperatingSystems', 'Browser', 'Region', 'TrafficType', 'VisitorType',\n",
    "       'Weekend'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Revenue'] = df['Revenue'].replace(False,0)\n",
    "train_y = np.array(df['Revenue'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = np.array(df_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12330, 75)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "rescaledX = scaler.fit_transform(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/ipykernel_launcher.py:2: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(24, input_dim=75, activation=\"relu\", kernel_initializer=\"uniform\")`\n",
      "  \n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(12, activation=\"relu\", kernel_initializer=\"uniform\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(6, activation=\"relu\", kernel_initializer=\"uniform\")`\n",
      "  after removing the cwd from sys.path.\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1, activation=\"sigmoid\", kernel_initializer=\"uniform\")`\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(24, input_dim=75, init='uniform', activation='relu'))\n",
    "model.add(Dense(12, init='uniform', activation='relu'))\n",
    "model.add(Dense(6, init='uniform', activation='relu'))\n",
    "model.add(Dense(1, init='uniform', activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/keras/models.py:981: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "12330/12330 [==============================] - 1s 72us/step - loss: 0.5584 - acc: 0.8453\n",
      "Epoch 2/100\n",
      "12330/12330 [==============================] - 0s 35us/step - loss: 0.4001 - acc: 0.8453\n",
      "Epoch 3/100\n",
      "12330/12330 [==============================] - 0s 38us/step - loss: 0.3790 - acc: 0.8453\n",
      "Epoch 4/100\n",
      "12330/12330 [==============================] - 0s 30us/step - loss: 0.3662 - acc: 0.8453\n",
      "Epoch 5/100\n",
      "12330/12330 [==============================] - 0s 32us/step - loss: 0.3554 - acc: 0.8453\n",
      "Epoch 6/100\n",
      "12330/12330 [==============================] - 0s 40us/step - loss: 0.3444 - acc: 0.8453\n",
      "Epoch 7/100\n",
      "12330/12330 [==============================] - 0s 36us/step - loss: 0.3342 - acc: 0.8453\n",
      "Epoch 8/100\n",
      "12330/12330 [==============================] - 0s 35us/step - loss: 0.3227 - acc: 0.8453\n",
      "Epoch 9/100\n",
      "12330/12330 [==============================] - 1s 49us/step - loss: 0.3118 - acc: 0.8693\n",
      "Epoch 10/100\n",
      "12330/12330 [==============================] - 0s 37us/step - loss: 0.3003 - acc: 0.8783\n",
      "Epoch 11/100\n",
      "12330/12330 [==============================] - 0s 36us/step - loss: 0.2902 - acc: 0.8832\n",
      "Epoch 12/100\n",
      "12330/12330 [==============================] - 0s 33us/step - loss: 0.2806 - acc: 0.8878\n",
      "Epoch 13/100\n",
      "12330/12330 [==============================] - 0s 34us/step - loss: 0.2739 - acc: 0.8916\n",
      "Epoch 14/100\n",
      "12330/12330 [==============================] - 1s 43us/step - loss: 0.2675 - acc: 0.8930\n",
      "Epoch 15/100\n",
      "12330/12330 [==============================] - 0s 37us/step - loss: 0.2632 - acc: 0.8953\n",
      "Epoch 16/100\n",
      "12330/12330 [==============================] - 0s 35us/step - loss: 0.2596 - acc: 0.8964\n",
      "Epoch 17/100\n",
      "12330/12330 [==============================] - 0s 37us/step - loss: 0.2573 - acc: 0.8964\n",
      "Epoch 18/100\n",
      "12330/12330 [==============================] - 1s 41us/step - loss: 0.2544 - acc: 0.8951\n",
      "Epoch 19/100\n",
      "12330/12330 [==============================] - 0s 33us/step - loss: 0.2510 - acc: 0.8976\n",
      "Epoch 20/100\n",
      "12330/12330 [==============================] - 0s 35us/step - loss: 0.2484 - acc: 0.8980\n",
      "Epoch 21/100\n",
      "12330/12330 [==============================] - 0s 35us/step - loss: 0.2470 - acc: 0.8980\n",
      "Epoch 22/100\n",
      "12330/12330 [==============================] - 1s 45us/step - loss: 0.2437 - acc: 0.8991\n",
      "Epoch 23/100\n",
      "12330/12330 [==============================] - 0s 35us/step - loss: 0.2412 - acc: 0.8993\n",
      "Epoch 24/100\n",
      "12330/12330 [==============================] - 1s 45us/step - loss: 0.2414 - acc: 0.9001\n",
      "Epoch 25/100\n",
      "12330/12330 [==============================] - 0s 35us/step - loss: 0.2378 - acc: 0.9013\n",
      "Epoch 26/100\n",
      "12330/12330 [==============================] - 0s 34us/step - loss: 0.2377 - acc: 0.9014\n",
      "Epoch 27/100\n",
      "12330/12330 [==============================] - 1s 55us/step - loss: 0.2345 - acc: 0.9022\n",
      "Epoch 28/100\n",
      "12330/12330 [==============================] - 1s 43us/step - loss: 0.2339 - acc: 0.9011\n",
      "Epoch 29/100\n",
      "12330/12330 [==============================] - 0s 37us/step - loss: 0.2320 - acc: 0.9028\n",
      "Epoch 30/100\n",
      "12330/12330 [==============================] - 0s 38us/step - loss: 0.2310 - acc: 0.9039\n",
      "Epoch 31/100\n",
      "12330/12330 [==============================] - 1s 45us/step - loss: 0.2298 - acc: 0.9034\n",
      "Epoch 32/100\n",
      "12330/12330 [==============================] - 0s 37us/step - loss: 0.2288 - acc: 0.9021\n",
      "Epoch 33/100\n",
      "12330/12330 [==============================] - 1s 43us/step - loss: 0.2272 - acc: 0.9038\n",
      "Epoch 34/100\n",
      "12330/12330 [==============================] - 1s 47us/step - loss: 0.2271 - acc: 0.9041\n",
      "Epoch 35/100\n",
      "12330/12330 [==============================] - 0s 31us/step - loss: 0.2245 - acc: 0.9037\n",
      "Epoch 36/100\n",
      "12330/12330 [==============================] - 0s 30us/step - loss: 0.2244 - acc: 0.9045\n",
      "Epoch 37/100\n",
      "12330/12330 [==============================] - 0s 30us/step - loss: 0.2225 - acc: 0.9052\n",
      "Epoch 38/100\n",
      "12330/12330 [==============================] - 0s 33us/step - loss: 0.2235 - acc: 0.9052\n",
      "Epoch 39/100\n",
      "12330/12330 [==============================] - 1s 48us/step - loss: 0.2212 - acc: 0.9056\n",
      "Epoch 40/100\n",
      "12330/12330 [==============================] - 0s 31us/step - loss: 0.2203 - acc: 0.9066\n",
      "Epoch 41/100\n",
      "12330/12330 [==============================] - 0s 31us/step - loss: 0.2201 - acc: 0.9066\n",
      "Epoch 42/100\n",
      "12330/12330 [==============================] - 0s 34us/step - loss: 0.2176 - acc: 0.9075\n",
      "Epoch 43/100\n",
      "12330/12330 [==============================] - 0s 37us/step - loss: 0.2187 - acc: 0.9071\n",
      "Epoch 44/100\n",
      "12330/12330 [==============================] - 0s 30us/step - loss: 0.2174 - acc: 0.9065\n",
      "Epoch 45/100\n",
      "12330/12330 [==============================] - 0s 32us/step - loss: 0.2168 - acc: 0.9064\n",
      "Epoch 46/100\n",
      "12330/12330 [==============================] - 0s 29us/step - loss: 0.2156 - acc: 0.9077\n",
      "Epoch 47/100\n",
      "12330/12330 [==============================] - 0s 38us/step - loss: 0.2155 - acc: 0.9082\n",
      "Epoch 48/100\n",
      "12330/12330 [==============================] - 0s 40us/step - loss: 0.2140 - acc: 0.9082\n",
      "Epoch 49/100\n",
      "12330/12330 [==============================] - 0s 31us/step - loss: 0.2131 - acc: 0.9085\n",
      "Epoch 50/100\n",
      "12330/12330 [==============================] - 0s 29us/step - loss: 0.2139 - acc: 0.9092\n",
      "Epoch 51/100\n",
      "12330/12330 [==============================] - 0s 35us/step - loss: 0.2123 - acc: 0.9069\n",
      "Epoch 52/100\n",
      "12330/12330 [==============================] - 0s 31us/step - loss: 0.2116 - acc: 0.9090\n",
      "Epoch 53/100\n",
      "12330/12330 [==============================] - 0s 29us/step - loss: 0.2110 - acc: 0.9097\n",
      "Epoch 54/100\n",
      "12330/12330 [==============================] - 0s 30us/step - loss: 0.2098 - acc: 0.9079\n",
      "Epoch 55/100\n",
      "12330/12330 [==============================] - 0s 32us/step - loss: 0.2100 - acc: 0.9091\n",
      "Epoch 56/100\n",
      "12330/12330 [==============================] - 0s 34us/step - loss: 0.2091 - acc: 0.9098\n",
      "Epoch 57/100\n",
      "12330/12330 [==============================] - 0s 32us/step - loss: 0.2094 - acc: 0.9088\n",
      "Epoch 58/100\n",
      "12330/12330 [==============================] - 0s 31us/step - loss: 0.2091 - acc: 0.9092\n",
      "Epoch 59/100\n",
      "12330/12330 [==============================] - 0s 31us/step - loss: 0.2085 - acc: 0.9096\n",
      "Epoch 60/100\n",
      "12330/12330 [==============================] - 0s 37us/step - loss: 0.2075 - acc: 0.9108\n",
      "Epoch 61/100\n",
      "12330/12330 [==============================] - 0s 31us/step - loss: 0.2084 - acc: 0.9092\n",
      "Epoch 62/100\n",
      "12330/12330 [==============================] - 1s 41us/step - loss: 0.2054 - acc: 0.9101\n",
      "Epoch 63/100\n",
      "12330/12330 [==============================] - 0s 33us/step - loss: 0.2058 - acc: 0.9107\n",
      "Epoch 64/100\n",
      "12330/12330 [==============================] - 0s 34us/step - loss: 0.2061 - acc: 0.9111\n",
      "Epoch 65/100\n",
      "12330/12330 [==============================] - 1s 48us/step - loss: 0.2046 - acc: 0.9110\n",
      "Epoch 66/100\n",
      "12330/12330 [==============================] - 0s 30us/step - loss: 0.2056 - acc: 0.9106\n",
      "Epoch 67/100\n",
      "12330/12330 [==============================] - 0s 38us/step - loss: 0.2046 - acc: 0.9116\n",
      "Epoch 68/100\n",
      "12330/12330 [==============================] - 1s 43us/step - loss: 0.2054 - acc: 0.9107\n",
      "Epoch 69/100\n",
      "12330/12330 [==============================] - 1s 49us/step - loss: 0.2039 - acc: 0.9118\n",
      "Epoch 70/100\n",
      "12330/12330 [==============================] - 0s 31us/step - loss: 0.2022 - acc: 0.9118\n",
      "Epoch 71/100\n",
      "12330/12330 [==============================] - 0s 32us/step - loss: 0.2025 - acc: 0.9124\n",
      "Epoch 72/100\n",
      "12330/12330 [==============================] - 1s 50us/step - loss: 0.2020 - acc: 0.9130\n",
      "Epoch 73/100\n",
      "12330/12330 [==============================] - 0s 34us/step - loss: 0.2018 - acc: 0.9121\n",
      "Epoch 74/100\n",
      "12330/12330 [==============================] - 0s 37us/step - loss: 0.2006 - acc: 0.9148\n",
      "Epoch 75/100\n",
      "12330/12330 [==============================] - 1s 49us/step - loss: 0.1994 - acc: 0.9128\n",
      "Epoch 76/100\n",
      "12330/12330 [==============================] - 0s 34us/step - loss: 0.2009 - acc: 0.9137\n",
      "Epoch 77/100\n",
      "12330/12330 [==============================] - 1s 46us/step - loss: 0.1995 - acc: 0.9146\n",
      "Epoch 78/100\n",
      "12330/12330 [==============================] - 0s 35us/step - loss: 0.1992 - acc: 0.9148\n",
      "Epoch 79/100\n",
      "12330/12330 [==============================] - 1s 44us/step - loss: 0.1989 - acc: 0.9137\n",
      "Epoch 80/100\n",
      "12330/12330 [==============================] - 1s 44us/step - loss: 0.1976 - acc: 0.9142\n",
      "Epoch 81/100\n",
      "12330/12330 [==============================] - 0s 33us/step - loss: 0.1978 - acc: 0.9142\n",
      "Epoch 82/100\n",
      "12330/12330 [==============================] - 0s 36us/step - loss: 0.1989 - acc: 0.9139\n",
      "Epoch 83/100\n",
      "12330/12330 [==============================] - 1s 43us/step - loss: 0.1980 - acc: 0.9155\n",
      "Epoch 84/100\n",
      "12330/12330 [==============================] - 0s 35us/step - loss: 0.1974 - acc: 0.9132\n",
      "Epoch 85/100\n",
      "12330/12330 [==============================] - 0s 35us/step - loss: 0.1963 - acc: 0.9163\n",
      "Epoch 86/100\n",
      "12330/12330 [==============================] - 0s 33us/step - loss: 0.1974 - acc: 0.9131\n",
      "Epoch 87/100\n",
      "12330/12330 [==============================] - 1s 48us/step - loss: 0.1964 - acc: 0.9139\n",
      "Epoch 88/100\n",
      "12330/12330 [==============================] - 0s 38us/step - loss: 0.1951 - acc: 0.9152\n",
      "Epoch 89/100\n",
      "12330/12330 [==============================] - 0s 35us/step - loss: 0.1950 - acc: 0.9164\n",
      "Epoch 90/100\n",
      "12330/12330 [==============================] - 1s 44us/step - loss: 0.1949 - acc: 0.9169\n",
      "Epoch 91/100\n",
      "12330/12330 [==============================] - 0s 38us/step - loss: 0.1954 - acc: 0.9164\n",
      "Epoch 92/100\n",
      "12330/12330 [==============================] - 0s 31us/step - loss: 0.1938 - acc: 0.9165\n",
      "Epoch 93/100\n",
      "12330/12330 [==============================] - 0s 31us/step - loss: 0.1932 - acc: 0.9157\n",
      "Epoch 94/100\n",
      "12330/12330 [==============================] - 0s 34us/step - loss: 0.1955 - acc: 0.9171\n",
      "Epoch 95/100\n",
      "12330/12330 [==============================] - 1s 43us/step - loss: 0.1926 - acc: 0.9161\n",
      "Epoch 96/100\n",
      "12330/12330 [==============================] - 0s 33us/step - loss: 0.1946 - acc: 0.9144\n",
      "Epoch 97/100\n",
      "12330/12330 [==============================] - 0s 39us/step - loss: 0.1941 - acc: 0.9158\n",
      "Epoch 98/100\n",
      "12330/12330 [==============================] - 1s 48us/step - loss: 0.1932 - acc: 0.9152\n",
      "Epoch 99/100\n",
      "12330/12330 [==============================] - 1s 42us/step - loss: 0.1930 - acc: 0.9170\n",
      "Epoch 100/100\n",
      "12330/12330 [==============================] - 0s 38us/step - loss: 0.1920 - acc: 0.9173\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "history = model.fit(rescaledX, train_y, nb_epoch=100, batch_size=100,  verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12330/12330 [==============================] - 1s 54us/step\n",
      "acc: 91.97%\n"
     ]
    }
   ],
   "source": [
    "# Print Accuracy\n",
    "scores = model.evaluate(rescaledX, train_y) \n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.5315018e-05],\n",
       "       [7.3453224e-01],\n",
       "       [1.9569106e-02],\n",
       "       [7.3453224e-01],\n",
       "       [7.3453224e-01]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(rescaledX[195:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y[:200]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "conda-env-python-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
